{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataset\n",
    "\n",
    "To creat a dataset, I scrape reviews from [seek.com.au](https://www.seek.com.au/) for two companies __`Woolworths`__ and __`Coles`__ which both have a fair number of reviews.\n",
    "\n",
    "To avoid `JavaScript` obstructions (downloading webpage source before target content is loaded) I use __`selenium`__ along with __`BeautifulSoup`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woolworths Reviews\n",
    "\n",
    "Having a look at Woolworth [reviews](https://www.seek.com.au/companies/woolworths-supermarkets-432295/reviews) it can be observed that:\n",
    "1. reviews are delivered over __96__ different pages\n",
    "2. each review link has `html tag <a>` and `class = '_2gLKVsp'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/companies/woolworths-supermarkets-432295/reviews/2276877'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = requests.get('https://www.seek.com.au/companies/woolworths-supermarkets-432295/reviews')\n",
    "soup = BeautifulSoup(content.text, 'html.parser')\n",
    "links = soup.find('div', {'class' : '_1Y5kUMd'}).find_all('a', {'class' : '_2gLKVsp'})\n",
    "links[0]['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's scrape all the review links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "browser = webdriver.Firefox()\n",
    "woolies = []\n",
    "\n",
    "for page in range(1, 97):\n",
    "    url = 'https://www.seek.com.au/companies/woolworths-supermarkets-432295/reviews?page={}'.format(page)\n",
    "    browser.get(url)\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = soup.find('div', {'class' : '_1Y5kUMd'}).find_all('a', {'class' : '_2gLKVsp'})\n",
    "        \n",
    "    for link in links:\n",
    "        woolies.append(\"https://www.seek.com.au{}\".format(link['href']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "To save all the 1908 links in a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('woolies_urls.txt', 'w') as file:\n",
    "    for url in woolies:\n",
    "        file.write('{}\\n'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.seek.com.au/companies/woolworths-supermarkets-432295/reviews/2276877',\n",
       " 'https://www.seek.com.au/companies/woolworths-supermarkets-432295/reviews/256376',\n",
       " 'https://www.seek.com.au/companies/woolworths-supermarkets-432295/reviews/340048',\n",
       " 'https://www.seek.com.au/companies/woolworths-supermarkets-432295/reviews/277368',\n",
       " 'https://www.seek.com.au/companies/woolworths-supermarkets-432295/reviews/197028']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woolies[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During scraping below, it happens often that process becomes interrupted probably because site is lagging behind to load completely while data is fetched. However, with one of errors it became known that one of linkes is faulty and should be removed from the list:\n",
    "\n",
    "`woolies[1277]`  \n",
    "`https://www.seek.com.au/companies/woolworths-supermarkets-432295/reviews/35519`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.seek.com.au/companies/woolworths-supermarkets-432295/reviews/35519'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woolies.pop(1277)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scrape reviews and some other data and save them in a `csv` format file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "browser = webdriver.Firefox()\n",
    "\n",
    "with open('RawData.csv', 'a+', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for url in woolies:\n",
    "        browser.get(url)\n",
    "        review = browser.page_source\n",
    "        soup = BeautifulSoup(review, 'html.parser')\n",
    "\n",
    "        company = 'Woolworths'\n",
    "        review = soup.find('span', {'data-automation' : 'reviewCardFull-pros'}).text + \"\\n\" + soup.find(\n",
    "            'span', {'data-automation' : 'reviewCardFull-cons'}).text\n",
    "        rating = soup.find('span', {'class' : '_1erK2ob'}).text\n",
    "        review_date = soup.find('span', {'class' : '_3FrNV7v _38Keb0I _2QG7TNq E6m4BZb'}).text\n",
    "        time_stamp = datetime.today().strftime('%Y, %B')\n",
    "        \n",
    "        datawriter.writerow([company, review, rating, review_date, time_stamp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coles Reviews\n",
    "\n",
    "Time to run same process for `Coles`. So:\n",
    "1. `tags` and `classes` are the same.\n",
    "2. reviews are delivered upon 104 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Firefox()\n",
    "coles = []\n",
    "\n",
    "for page in range(1, 105):\n",
    "    url = 'https://www.seek.com.au/companies/coles-supermarkets-432309/reviews?page={}'.format(page)\n",
    "    browser.get(url)\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = soup.find('div', {'class' : '_1Y5kUMd'}).find_all('a', {'class' : '_2gLKVsp'})\n",
    "        \n",
    "    for link in links:\n",
    "        coles.append(\"https://www.seek.com.au{}\".format(link['href']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save all the review's link in a text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coles_urls.txt', 'w+') as file:\n",
    "    for url in coles:\n",
    "        file.write('{}\\n'.format(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, time to collect reviews and add it to the raw dataset:\n",
    "\n",
    "following links are fulty and should be removed:  \n",
    "coles[245]\n",
    "https://www.seek.com.au/companies/coles-supermarkets-432309/reviews/61321  \n",
    "coles[794]\n",
    "https://www.seek.com.au/companies/coles-supermarkets-432309/reviews/40365  \n",
    "coles[1600]\n",
    "https://www.seek.com.au/companies/coles-supermarkets-432309/reviews/52050  \n",
    "coles[1704]\n",
    "https://www.seek.com.au/companies/coles-supermarkets-432309/reviews/40431  \n",
    "coles[1712]\n",
    "https://www.seek.com.au/companies/coles-supermarkets-432309/reviews/52054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coles.remove('https://www.seek.com.au/companies/coles-supermarkets-432309/reviews/61321')\n",
    "coles.remove('https://www.seek.com.au/companies/coles-supermarkets-432309/reviews/40365')\n",
    "coles.remove('https://www.seek.com.au/companies/coles-supermarkets-432309/reviews/52050')\n",
    "coles.remove('https://www.seek.com.au/companies/coles-supermarkets-432309/reviews/40431')\n",
    "coles.remove('https://www.seek.com.au/companies/coles-supermarkets-432309/reviews/52054')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Firefox()\n",
    "\n",
    "with open('RawData.csv', 'a+', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for url in coles:\n",
    "        browser.get(url)\n",
    "        review = browser.page_source\n",
    "        soup = BeautifulSoup(review, 'html.parser')\n",
    "\n",
    "        company = 'Coles'\n",
    "        review = soup.find('span', {'data-automation' : 'reviewCardFull-pros'}).text + \"\\n\" + soup.find(\n",
    "            'span', {'data-automation' : 'reviewCardFull-cons'}).text\n",
    "        rating = soup.find('span', {'class' : '_1erK2ob'}).text\n",
    "        review_date = soup.find('span', {'class' : '_3FrNV7v _38Keb0I _2QG7TNq E6m4BZb'}).text\n",
    "        time_stamp = datetime.today().strftime('%Y, %B')\n",
    "        \n",
    "        datawriter.writerow([company, review, rating, review_date, time_stamp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALDI Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching all urls for aldi's reviews\n",
    "\n",
    "browser = webdriver.Firefox()\n",
    "ALDI = []\n",
    "\n",
    "for page in range(25, 26):\n",
    "    url = 'https://www.seek.com.au/companies/aldi-432489/reviews?page={}'.format(page)\n",
    "    browser.get(url)\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = soup.find('div', {'class' : '_1Y5kUMd'}).find_all('a', {'class' : '_2gLKVsp'})\n",
    "        \n",
    "    for link in links:\n",
    "        ALDI.append(\"https://www.seek.com.au{}\".format(link['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# writing aldi's urls into a text file\n",
    "\n",
    "with open('aldi.txt', 'w+') as file:\n",
    "    for url in ALDI:\n",
    "        file.write('{}\\n'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faulty links to remove\n",
    "ALDI.remove('https://www.seek.com.au/companies/aldi-432489/reviews/61903')\n",
    "ALDI.remove('https://www.seek.com.au/companies/aldi-432489/reviews/40163')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Firefox()\n",
    "\n",
    "with open('RawData.csv', 'a+', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for url in ALDI[344:]:\n",
    "        browser.get(url)\n",
    "        review = browser.page_source\n",
    "        soup = BeautifulSoup(review, 'html.parser')\n",
    "        \n",
    "        company = 'ALDI'\n",
    "        review = soup.find('span', {'data-automation' : 'reviewCardFull-pros'}).text + \"\\n\" + soup.find(\n",
    "            'span', {'data-automation' : 'reviewCardFull-cons'}).text\n",
    "        rating = soup.find('span', {'class' : '_1erK2ob'}).text\n",
    "        review_date = soup.find('span', {'class' : '_3FrNV7v _38Keb0I _2QG7TNq E6m4BZb'}).text\n",
    "        time_stamp = datetime.today().strftime('%Y, %B')\n",
    "        \n",
    "        datawriter.writerow([company, review, rating, review_date, time_stamp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what has been collected so far: `(4,468 reviews)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching all urls for Kmart's reviews\n",
    "\n",
    "browser = webdriver.Firefox()\n",
    "kmart = []\n",
    "\n",
    "for page in range(1, 40):\n",
    "    url = 'https://www.seek.com.au/companies/kmart-432302/reviews?page={}'.format(page)\n",
    "    browser.get(url)\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = soup.find('div', {'class' : '_1Y5kUMd'}).find_all('a', {'class' : '_2gLKVsp'})\n",
    "        \n",
    "    for link in links:\n",
    "        kmart.append(\"https://www.seek.com.au{}\".format(link['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing kmarts's urls into a text file\n",
    "\n",
    "with open('kmart.txt', 'w+') as file:\n",
    "    for url in kmart:\n",
    "        file.write('{}\\n'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faulty links to remove\n",
    "kmart.remove('https://www.seek.com.au/companies/kmart-432302/reviews/41755')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Firefox()\n",
    "\n",
    "counter = 574\n",
    "\n",
    "with open('RawData.csv', 'a+', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for url in kmart[574:]:\n",
    "        browser.get(url)\n",
    "        review = browser.page_source\n",
    "        soup = BeautifulSoup(review, 'html.parser')\n",
    "        \n",
    "        print(counter, end='\\t')\n",
    "        counter += 1\n",
    "        \n",
    "        company = 'Kmart'\n",
    "        review = soup.find('span', {'data-automation' : 'reviewCardFull-pros'}).text + \"\\n\" + soup.find(\n",
    "            'span', {'data-automation' : 'reviewCardFull-cons'}).text\n",
    "        rating = soup.find('span', {'class' : '_1erK2ob'}).text\n",
    "        review_date = soup.find('span', {'class' : '_3FrNV7v _38Keb0I _2QG7TNq E6m4BZb'}).text\n",
    "        time_stamp = datetime.today().strftime('%Y, %B')\n",
    "        \n",
    "        datawriter.writerow([company, review, rating, review_date, time_stamp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('RawData.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Woolworths</td>\n",
       "      <td>-Great working environment with very good supp...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2 years ago</td>\n",
       "      <td>2020, January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Woolworths</td>\n",
       "      <td>I enjoyed what I am doing, it's a tough job, b...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4 years ago</td>\n",
       "      <td>2020, January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Woolworths</td>\n",
       "      <td>Working with staff everyday. The ability to wo...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4 years ago</td>\n",
       "      <td>2020, January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Woolworths</td>\n",
       "      <td>Great opportunities for career advancement for...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4 years ago</td>\n",
       "      <td>2020, January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Woolworths</td>\n",
       "      <td>During peek sales periods; casuals get great h...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4 years ago</td>\n",
       "      <td>2020, January</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                                                  1    2  \\\n",
       "0  Woolworths  -Great working environment with very good supp...  5.0   \n",
       "1  Woolworths  I enjoyed what I am doing, it's a tough job, b...  3.0   \n",
       "2  Woolworths  Working with staff everyday. The ability to wo...  4.0   \n",
       "3  Woolworths  Great opportunities for career advancement for...  4.0   \n",
       "4  Woolworths  During peek sales periods; casuals get great h...  3.0   \n",
       "\n",
       "             3              4  \n",
       "0  2 years ago  2020, January  \n",
       "1  4 years ago  2020, January  \n",
       "2  4 years ago  2020, January  \n",
       "3  4 years ago  2020, January  \n",
       "4  4 years ago  2020, January  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5247, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
