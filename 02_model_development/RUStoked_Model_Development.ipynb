{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from time import time\n",
    "\n",
    "# sklearn utility imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# sklearn classifier imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# \"gensim\" modules\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.sklearn_api import W2VTransformer\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../01_data_preparation/pickle_cleaned_data', 'rb') as data:\n",
    "    df = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_cleaned</th>\n",
       "      <th>sentiment_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-Great working environment with very good supp...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I enjoyed what I am doing, it's a tough job, b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Working with staff everyday. The ability to wo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great opportunities for career advancement for...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>During peek sales periods; casuals get great h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      review_cleaned  sentiment_category\n",
       "0  -Great working environment with very good supp...                   2\n",
       "1  I enjoyed what I am doing, it's a tough job, b...                   1\n",
       "2  Working with staff everyday. The ability to wo...                   2\n",
       "3  Great opportunities for career advancement for...                   2\n",
       "4  During peek sales periods; casuals get great h...                   1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train, reviews_test, rating_train_target, rating_test_target = train_test_split(\n",
    "    df['review_cleaned'], \n",
    "    df['sentiment_category'], \n",
    "    test_size=0.2, \n",
    "    random_state=69, \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "following model `parameters` have been manually altered one by one or two by two and run through `GridSearchCV()` for optimized parameters (Running grid search on all parameters option is highly time and resource consuming for a mid-level PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': [], 'train_score': [], 'test_score': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to keep track of each model result\n",
    "result = {'model': [], 'train_score': [], 'test_score': []}\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), \n",
    "    ('RFclf', RandomForestClassifier(random_state=69))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__lowercase': (False,),\n",
    "    'tfidf__ngram_range': ((1, 2),), \n",
    "    'tfidf__max_df': (0.5,), \n",
    "    'tfidf__min_df': (1,), \n",
    "    'tfidf__max_features': (5000,), \n",
    "    'tfidf__norm': ('l2',), \n",
    "    'tfidf__use_idf': (True,), \n",
    "    'RFclf__n_estimators': (100,), \n",
    "    'RFclf__max_depth': (100,), \n",
    "    'RFclf__min_samples_split': (5,),\n",
    "    'RFclf__min_samples_leaf': (1,), \n",
    "    'RFclf__max_features': ('auto',), \n",
    "    'RFclf__bootstrap': (True,)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 9.080s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #rand_search = RandomizedSearchCV(pipeline, parameters, n_iter=100, n_jobs=-1, verbose=2)\n",
    "    grid_search = GridSearchCV(pipeline, parameters, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "    t0 = time()\n",
    "    #rand_search.fit(reviews_train, rating_train_target)\n",
    "    grid_search.fit(reviews_train, rating_train_target)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.626\n"
     ]
    }
   ],
   "source": [
    "print(\"{:0.3f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RFclf__bootstrap': True,\n",
       " 'RFclf__max_depth': 100,\n",
       " 'RFclf__max_features': 'auto',\n",
       " 'RFclf__min_samples_leaf': 1,\n",
       " 'RFclf__min_samples_split': 5,\n",
       " 'RFclf__n_estimators': 100,\n",
       " 'tfidf__lowercase': False,\n",
       " 'tfidf__max_df': 0.5,\n",
       " 'tfidf__max_features': 5000,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__use_idf': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6134800550206327"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(reviews_test, rating_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of this model results\n",
    "result['model'].append('Random Forest')\n",
    "result['train_score'].append(\"{:0.3f}\".format(grid_search.best_score_))\n",
    "result['test_score'].append(\"{:0.3f}\".format(grid_search.score(reviews_test, rating_test_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), \n",
    "    ('LRclf', LogisticRegression(random_state=69))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__lowercase': (False,),\n",
    "    'tfidf__ngram_range': ((1, 2),), \n",
    "    'tfidf__max_df': (0.5,), \n",
    "    'tfidf__min_df': (1,), \n",
    "    'tfidf__max_features': (5000,), \n",
    "    'tfidf__norm': ('l2',), \n",
    "    'tfidf__use_idf': (True,), \n",
    "    'LRclf__penalty': ('l2',),\n",
    "    'LRclf__C': (1,), \n",
    "    'LRclf__class_weight': (None,), \n",
    "    'LRclf__solver': ('lbfgs',), \n",
    "    'LRclf__multi_class': ('auto',),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 3.065s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid_search = GridSearchCV(pipeline, parameters, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "    t0 = time()\n",
    "    grid_search.fit(reviews_train, rating_train_target)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.635\n"
     ]
    }
   ],
   "source": [
    "print(\"{:0.3f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LRclf__C': 1,\n",
       " 'LRclf__class_weight': None,\n",
       " 'LRclf__multi_class': 'auto',\n",
       " 'LRclf__penalty': 'l2',\n",
       " 'LRclf__solver': 'lbfgs',\n",
       " 'tfidf__lowercase': False,\n",
       " 'tfidf__max_df': 0.5,\n",
       " 'tfidf__max_features': 5000,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__use_idf': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6327372764786795"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(reviews_test, rating_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of this model results\n",
    "result['model'].append('Logistic Regression')\n",
    "result['train_score'].append(\"{:0.3f}\".format(grid_search.best_score_))\n",
    "result['test_score'].append(\"{:0.3f}\".format(grid_search.score(reviews_test, rating_test_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Spport Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), \n",
    "    ('SVMclf', svm.SVC(random_state=69))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__lowercase': (False,),\n",
    "    'tfidf__ngram_range': ((1, 2),), \n",
    "    'tfidf__max_df': (0.5,), \n",
    "    'tfidf__min_df': (1,), \n",
    "    'tfidf__max_features': (5000,), \n",
    "    'tfidf__norm': ('l2',), \n",
    "    'tfidf__use_idf': (True,), \n",
    "    'SVMclf__C': (1,), \n",
    "    'SVMclf__kernel': ('rbf',), \n",
    "    'SVMclf__degree': (1,), \n",
    "    'SVMclf__gamma': ('scale',), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 10.362s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid_search = GridSearchCV(pipeline, parameters, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "    t0 = time()\n",
    "    grid_search.fit(reviews_train, rating_train_target)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.645\n"
     ]
    }
   ],
   "source": [
    "print(\"{:0.3f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVMclf__C': 1,\n",
       " 'SVMclf__degree': 1,\n",
       " 'SVMclf__gamma': 'scale',\n",
       " 'SVMclf__kernel': 'rbf',\n",
       " 'tfidf__lowercase': False,\n",
       " 'tfidf__max_df': 0.5,\n",
       " 'tfidf__max_features': 5000,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__use_idf': True}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6341127922971114"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(reviews_test, rating_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of this model results\n",
    "result['model'].append('Support Vector')\n",
    "result['train_score'].append(\"{:0.3f}\".format(grid_search.best_score_))\n",
    "result['test_score'].append(\"{:0.3f}\".format(grid_search.score(reviews_test, rating_test_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multinomial Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), \n",
    "    ('NBclf', MultinomialNB())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__lowercase': (False,),\n",
    "    'tfidf__ngram_range': ((1, 2),), \n",
    "    'tfidf__max_df': (0.5,), \n",
    "    'tfidf__min_df': (1,), \n",
    "    'tfidf__max_features': (5000,), \n",
    "    'tfidf__norm': ('l2',), \n",
    "    'tfidf__use_idf': (True,), \n",
    "    'NBclf__alpha': (1,), \n",
    "    'NBclf__fit_prior': (False,), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.077s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid_search = GridSearchCV(pipeline, parameters, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "    t0 = time()\n",
    "    grid_search.fit(reviews_train, rating_train_target)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.631\n"
     ]
    }
   ],
   "source": [
    "print(\"{:0.3f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NBclf__alpha': 1,\n",
       " 'NBclf__fit_prior': False,\n",
       " 'tfidf__lowercase': False,\n",
       " 'tfidf__max_df': 0.5,\n",
       " 'tfidf__max_features': 5000,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__use_idf': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6368638239339752"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(reviews_test, rating_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of this model results\n",
    "result['model'].append('M Naive Bayes')\n",
    "result['train_score'].append(\"{:0.3f}\".format(grid_search.best_score_))\n",
    "result['test_score'].append(\"{:0.3f}\".format(grid_search.score(reviews_test, rating_test_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), \n",
    "    ('KNNclf', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__lowercase': (False,),\n",
    "    'tfidf__ngram_range': ((1, 2),), \n",
    "    'tfidf__max_df': (0.5,), \n",
    "    'tfidf__min_df': (1,), \n",
    "    'tfidf__max_features': (5000,), \n",
    "    'tfidf__norm': ('l2',), \n",
    "    'tfidf__use_idf': (True,), \n",
    "    'KNNclf__n_neighbors': (30,), \n",
    "    'KNNclf__weights': ('distance',),\n",
    "    'KNNclf__algorithm': ('auto',), \n",
    "    'KNNclf__leaf_size': (30,), \n",
    "    'KNNclf__p': (2,),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.442s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid_search = GridSearchCV(pipeline, parameters, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "    t0 = time()\n",
    "    grid_search.fit(reviews_train, rating_train_target)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.606\n"
     ]
    }
   ],
   "source": [
    "print(\"{:0.3f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNNclf__algorithm': 'auto',\n",
       " 'KNNclf__leaf_size': 30,\n",
       " 'KNNclf__n_neighbors': 30,\n",
       " 'KNNclf__p': 2,\n",
       " 'KNNclf__weights': 'distance',\n",
       " 'tfidf__lowercase': False,\n",
       " 'tfidf__max_df': 0.5,\n",
       " 'tfidf__max_features': 5000,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__use_idf': True}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6217331499312242"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(reviews_test, rating_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of this model results\n",
    "result['model'].append('K Nearest Neighbors')\n",
    "result['train_score'].append(\"{:0.3f}\".format(grid_search.best_score_))\n",
    "result['test_score'].append(\"{:0.3f}\".format(grid_search.score(reviews_test, rating_test_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), \n",
    "    ('GBclf', GradientBoostingClassifier(random_state=69))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__lowercase': (False,),\n",
    "    'tfidf__ngram_range': ((1, 2),), \n",
    "    'tfidf__max_df': (0.5,), \n",
    "    'tfidf__min_df': (1,), \n",
    "    'tfidf__max_features': (5000,), \n",
    "    'tfidf__norm': ('l2',), \n",
    "    'tfidf__use_idf': (True,), \n",
    "    'GBclf__loss': ('deviance',), \n",
    "    'GBclf__learning_rate': (0.1,), \n",
    "    'GBclf__n_estimators': (200,), \n",
    "    'GBclf__min_samples_split': (50, 100), \n",
    "    'GBclf__min_samples_leaf': (2,),\n",
    "    'GBclf__max_depth': (1, 3, 5), \n",
    "    'GBclf__max_features': ('sqrt',)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   46.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 48.937s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid_search = GridSearchCV(pipeline, parameters, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "    t0 = time()\n",
    "    grid_search.fit(reviews_train, rating_train_target)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.614\n"
     ]
    }
   ],
   "source": [
    "print(\"{:0.3f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GBclf__learning_rate': 0.1,\n",
       " 'GBclf__loss': 'deviance',\n",
       " 'GBclf__max_depth': 3,\n",
       " 'GBclf__max_features': 'sqrt',\n",
       " 'GBclf__min_samples_leaf': 2,\n",
       " 'GBclf__min_samples_split': 50,\n",
       " 'GBclf__n_estimators': 200,\n",
       " 'tfidf__lowercase': False,\n",
       " 'tfidf__max_df': 0.5,\n",
       " 'tfidf__max_features': 5000,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__use_idf': True}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5997248968363136"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(reviews_test, rating_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of this model results\n",
    "result['model'].append('Gradient Boosting')\n",
    "result['train_score'].append(\"{:0.3f}\".format(grid_search.best_score_))\n",
    "result['test_score'].append(\"{:0.3f}\".format(grid_search.score(reviews_test, rating_test_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models' Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M Naive Bayes</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model train_score test_score\n",
       "0        Random Forest       0.626      0.613\n",
       "1  Logistic Regression       0.635      0.633\n",
       "2       Support Vector       0.645      0.634\n",
       "3        M Naive Bayes       0.631      0.637\n",
       "4  K Nearest Neighbors       0.606      0.622\n",
       "5    Gradient Boosting       0.614      0.600"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply `Gensim`'s `word2vec` model, going to need to creat two `sklearn` compatible costomized transformers. one for tokenizing the input-text to `gensim` vectorizer and another to reduce the dimension of output vector by avaraging each word's vector before feeding the model.\n",
    "\n",
    "Reference : [Github](https://github.com/nadbordrozd/blog_stuff/blob/master/classification_w2v/benchmarking_python3.ipynb()https://github.com/nadbordrozd/blog_stuff/blob/master/classification_w2v/benchmarking_python3.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn compatible tokenizer class\n",
    "\n",
    "class custom_tokenizer(BaseEstimator, TransformerMixin):\n",
    "    '''sklearn compatible tokenizer'''\n",
    "    \n",
    "    def __init__(self, arg=None):\n",
    "        self.arg = arg\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return [word_tokenize(sentence) for sentence in X]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_array_mean(BaseEstimator, TransformerMixin):\n",
    "    '''avaraging each word's vector'''\n",
    "    \n",
    "    def __init__(self, wordvecs):\n",
    "        self.wordvecs = wordvecs\n",
    "        self.dim = len(wordvecs[next(iter(wordvecs))])\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # returns zero if word not in gensim  trained word2vec model\n",
    "        return np.array([\n",
    "            np.mean([self.wordvecs[word] for word in words if word in self.wordvecs] \n",
    "                    or [np.zeros(self.dim)], axis=0) for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# craeting a <<list of lists of tokens>> of all reviews to train gensim word2vec model\n",
    "corpus = custom_tokenizer().fit_transform(df['review_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakima/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Training the gensim's word2vec model and creating / mapping the word-vectors\n",
    "w2v_model = Word2Vec(corpus, size=50, window=5, min_count=3, workers=2)\n",
    "wordvecs = {word: vec for word, vec in zip(w2v_model.wv.index2word, w2v_model.wv.syn0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option for loading a pre-trained GloVe model\n",
    "# see https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "wordvecs = {}\n",
    "\n",
    "all_words = [word for sentence in corpus for word in sentence]\n",
    "\n",
    "with open(\"glove.6B.50d.txt\", \"rb\") as model:\n",
    "    for line in model:\n",
    "        tokenized_line = line.split()\n",
    "        word = tokenized_line[0].decode('utf8')\n",
    "        if word in all_words:\n",
    "            vectors = np.array(tokenized_line[1:], dtype=np.float32)\n",
    "            \n",
    "            wordvecs[word] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tknz', custom_tokenizer()), \n",
    "    ('w2vec', custom_array_mean(wordvecs)), \n",
    "    ('SVMclf', svm.SVC(random_state=69))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'SVMclf__C': (1,), \n",
    "    'SVMclf__kernel': ('rbf',), \n",
    "    'SVMclf__degree': (1,), \n",
    "    'SVMclf__gamma': ('scale',), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   31.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   31.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 34.586s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid_search = GridSearchCV(pipeline, parameters, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "    t0 = time()\n",
    "    grid_search.fit(reviews_train, rating_train_target)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.565\n"
     ]
    }
   ],
   "source": [
    "print(\"{:0.3f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.579092159559835"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(reviews_test, rating_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
